{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc61ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is from the transformer.py file\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb582ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                      '।','0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
    "                      'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', \n",
    "                      'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', \n",
    "                      'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', \n",
    "                      'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', \n",
    "                      'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', \n",
    "                      'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', \n",
    "                      'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', \n",
    "                      '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', \n",
    "                      '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "hindi_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
    "                    '।','0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ',\n",
    "                    'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ',\n",
    "                    'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह',\n",
    "                    '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॐ',\n",
    "                    '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ',\n",
    "                    '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f983ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '।', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', 'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', 'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', 'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', 'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', 'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', 'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', 'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', '<PADDING>', '<END>']\n",
      "['<START>', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '।', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '<PADDING>', '<END>']\n"
     ]
    }
   ],
   "source": [
    "print(kannada_vocabulary)\n",
    "print(hindi_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886a575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_hindi = {k:v for k,v in enumerate(hindi_vocabulary)}\n",
    "hindi_to_index = {v:k for k,v in enumerate(hindi_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "688379dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : Kannada\n",
      "{0: '<START>', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '।', 18: '0', 19: '1', 20: '2', 21: '3', 22: '4', 23: '5', 24: '6', 25: '7', 26: '8', 27: '9', 28: ':', 29: '<', 30: '=', 31: '>', 32: '?', 33: 'ˌ', 34: 'ँ', 35: 'ఆ', 36: 'ఇ', 37: 'ా', 38: 'ి', 39: 'ీ', 40: 'ు', 41: 'ూ', 42: 'ಅ', 43: 'ಆ', 44: 'ಇ', 45: 'ಈ', 46: 'ಉ', 47: 'ಊ', 48: 'ಋ', 49: 'ೠ', 50: 'ಌ', 51: 'ಎ', 52: 'ಏ', 53: 'ಐ', 54: 'ಒ', 55: 'ಓ', 56: 'ಔ', 57: 'ಕ', 58: 'ಖ', 59: 'ಗ', 60: 'ಘ', 61: 'ಙ', 62: 'ಚ', 63: 'ಛ', 64: 'ಜ', 65: 'ಝ', 66: 'ಞ', 67: 'ಟ', 68: 'ಠ', 69: 'ಡ', 70: 'ಢ', 71: 'ಣ', 72: 'ತ', 73: 'ಥ', 74: 'ದ', 75: 'ಧ', 76: 'ನ', 77: 'ಪ', 78: 'ಫ', 79: 'ಬ', 80: 'ಭ', 81: 'ಮ', 82: 'ಯ', 83: 'ರ', 84: 'ಱ', 85: 'ಲ', 86: 'ಳ', 87: 'ವ', 88: 'ಶ', 89: 'ಷ', 90: 'ಸ', 91: 'ಹ', 92: '಼', 93: 'ಽ', 94: 'ಾ', 95: 'ಿ', 96: 'ೀ', 97: 'ು', 98: 'ೂ', 99: 'ೃ', 100: 'ೄ', 101: 'ೆ', 102: 'ೇ', 103: 'ೈ', 104: 'ೊ', 105: 'ೋ', 106: 'ೌ', 107: '್', 108: 'ೕ', 109: 'ೖ', 110: 'ೞ', 111: 'ೣ', 112: 'ಂ', 113: 'ಃ', 114: '೦', 115: '೧', 116: '೨', 117: '೩', 118: '೪', 119: '೫', 120: '೬', 121: '೭', 122: '೮', 123: '೯', 124: '<PADDING>', 125: '<END>'}\n",
      "\n",
      "Kannada : Index\n",
      "{'<START>': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '।': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, '<': 29, '=': 30, '>': 31, '?': 32, 'ˌ': 33, 'ँ': 34, 'ఆ': 35, 'ఇ': 36, 'ా': 37, 'ి': 38, 'ీ': 39, 'ు': 40, 'ూ': 41, 'ಅ': 42, 'ಆ': 43, 'ಇ': 44, 'ಈ': 45, 'ಉ': 46, 'ಊ': 47, 'ಋ': 48, 'ೠ': 49, 'ಌ': 50, 'ಎ': 51, 'ಏ': 52, 'ಐ': 53, 'ಒ': 54, 'ಓ': 55, 'ಔ': 56, 'ಕ': 57, 'ಖ': 58, 'ಗ': 59, 'ಘ': 60, 'ಙ': 61, 'ಚ': 62, 'ಛ': 63, 'ಜ': 64, 'ಝ': 65, 'ಞ': 66, 'ಟ': 67, 'ಠ': 68, 'ಡ': 69, 'ಢ': 70, 'ಣ': 71, 'ತ': 72, 'ಥ': 73, 'ದ': 74, 'ಧ': 75, 'ನ': 76, 'ಪ': 77, 'ಫ': 78, 'ಬ': 79, 'ಭ': 80, 'ಮ': 81, 'ಯ': 82, 'ರ': 83, 'ಱ': 84, 'ಲ': 85, 'ಳ': 86, 'ವ': 87, 'ಶ': 88, 'ಷ': 89, 'ಸ': 90, 'ಹ': 91, '಼': 92, 'ಽ': 93, 'ಾ': 94, 'ಿ': 95, 'ೀ': 96, 'ು': 97, 'ೂ': 98, 'ೃ': 99, 'ೄ': 100, 'ೆ': 101, 'ೇ': 102, 'ೈ': 103, 'ೊ': 104, 'ೋ': 105, 'ೌ': 106, '್': 107, 'ೕ': 108, 'ೖ': 109, 'ೞ': 110, 'ೣ': 111, 'ಂ': 112, 'ಃ': 113, '೦': 114, '೧': 115, '೨': 116, '೩': 117, '೪': 118, '೫': 119, '೬': 120, '೭': 121, '೮': 122, '೯': 123, '<PADDING>': 124, '<END>': 125}\n",
      "\n",
      "\n",
      "Index : Hindi\n",
      "{0: '<START>', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '।', 18: '0', 19: '1', 20: '2', 21: '3', 22: '4', 23: '5', 24: '6', 25: '7', 26: '8', 27: '9', 28: ':', 29: '<', 30: '=', 31: '>', 32: '?', 33: 'ऀ', 34: 'ँ', 35: 'ं', 36: 'ः', 37: 'ऄ', 38: 'अ', 39: 'आ', 40: 'इ', 41: 'ई', 42: 'उ', 43: 'ऊ', 44: 'ऋ', 45: 'ऌ', 46: 'ऍ', 47: 'ऎ', 48: 'ए', 49: 'ऐ', 50: 'ऑ', 51: 'ऒ', 52: 'ओ', 53: 'औ', 54: 'क', 55: 'ख', 56: 'ग', 57: 'घ', 58: 'ङ', 59: 'च', 60: 'छ', 61: 'ज', 62: 'झ', 63: 'ञ', 64: 'ट', 65: 'ठ', 66: 'ड', 67: 'ढ', 68: 'ण', 69: 'त', 70: 'थ', 71: 'द', 72: 'ध', 73: 'न', 74: 'प', 75: 'फ', 76: 'ब', 77: 'भ', 78: 'म', 79: 'य', 80: 'र', 81: 'ल', 82: 'ळ', 83: 'व', 84: 'श', 85: 'ष', 86: 'स', 87: 'ह', 88: '़', 89: 'ऽ', 90: 'ा', 91: 'ि', 92: 'ी', 93: 'ु', 94: 'ू', 95: 'ृ', 96: 'ॄ', 97: 'ॅ', 98: 'ॆ', 99: 'े', 100: 'ै', 101: 'ॉ', 102: 'ॊ', 103: 'ो', 104: 'ौ', 105: '्', 106: 'ॐ', 107: '॑', 108: '॒', 109: '॓', 110: '॔', 111: 'ॕ', 112: 'ॖ', 113: 'ॗ', 114: 'क़', 115: 'ख़', 116: 'ग़', 117: 'ज़', 118: 'ड़', 119: 'ढ़', 120: 'फ़', 121: 'य़', 122: 'ॠ', 123: 'ॡ', 124: 'ॢ', 125: 'ॣ', 126: '०', 127: '१', 128: '२', 129: '३', 130: '४', 131: '५', 132: '६', 133: '७', 134: '८', 135: '९', 136: '<PADDING>', 137: '<END>'}\n",
      "\n",
      "Hindi : Index\n",
      "{'<START>': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '।': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, '<': 29, '=': 30, '>': 31, '?': 32, 'ऀ': 33, 'ँ': 34, 'ं': 35, 'ः': 36, 'ऄ': 37, 'अ': 38, 'आ': 39, 'इ': 40, 'ई': 41, 'उ': 42, 'ऊ': 43, 'ऋ': 44, 'ऌ': 45, 'ऍ': 46, 'ऎ': 47, 'ए': 48, 'ऐ': 49, 'ऑ': 50, 'ऒ': 51, 'ओ': 52, 'औ': 53, 'क': 54, 'ख': 55, 'ग': 56, 'घ': 57, 'ङ': 58, 'च': 59, 'छ': 60, 'ज': 61, 'झ': 62, 'ञ': 63, 'ट': 64, 'ठ': 65, 'ड': 66, 'ढ': 67, 'ण': 68, 'त': 69, 'थ': 70, 'द': 71, 'ध': 72, 'न': 73, 'प': 74, 'फ': 75, 'ब': 76, 'भ': 77, 'म': 78, 'य': 79, 'र': 80, 'ल': 81, 'ळ': 82, 'व': 83, 'श': 84, 'ष': 85, 'स': 86, 'ह': 87, '़': 88, 'ऽ': 89, 'ा': 90, 'ि': 91, 'ी': 92, 'ु': 93, 'ू': 94, 'ृ': 95, 'ॄ': 96, 'ॅ': 97, 'ॆ': 98, 'े': 99, 'ै': 100, 'ॉ': 101, 'ॊ': 102, 'ो': 103, 'ौ': 104, '्': 105, 'ॐ': 106, '॑': 107, '॒': 108, '॓': 109, '॔': 110, 'ॕ': 111, 'ॖ': 112, 'ॗ': 113, 'क़': 114, 'ख़': 115, 'ग़': 116, 'ज़': 117, 'ड़': 118, 'ढ़': 119, 'फ़': 120, 'य़': 121, 'ॠ': 122, 'ॡ': 123, 'ॢ': 124, 'ॣ': 125, '०': 126, '१': 127, '२': 128, '३': 129, '४': 130, '५': 131, '६': 132, '७': 133, '८': 134, '९': 135, '<PADDING>': 136, '<END>': 137}\n"
     ]
    }
   ],
   "source": [
    "print(\"Index : Kannada\")\n",
    "print(index_to_kannada)\n",
    "print(\"\\nKannada : Index\")\n",
    "print(kannada_to_index)\n",
    "print(\"\\n\\nIndex : Hindi\")\n",
    "print(index_to_hindi)\n",
    "print(\"\\nHindi : Index\")\n",
    "print(hindi_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d01b34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/Hi-Kn/train.hi', 'r') as file:\n",
    "    hindi_sentences = file.readlines()\n",
    "with open('datasets/Hi-Kn/train.kn', 'r') as file:\n",
    "    kannada_sentences = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b17fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove special characters from the sentences\n",
    "def remove_special_characters(sentence):\n",
    "    return re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "# Preprocess the Hindi and Kannada sentences before further processing\n",
    "hindi_sentences = [remove_special_characters(sentence) for sentence in hindi_sentences]\n",
    "kannada_sentences = [remove_special_characters(sentence) for sentence in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9492afff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2148233, 2148233)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_sentences), len( kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a05996e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SENTENCES = 210000\n",
    "hindi_sentences = hindi_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "hindi_sentences = [sentence.rstrip('\\n').lower() for sentence in hindi_sentences]\n",
    "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7c0ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210000, 210000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_sentences), len( kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30bdfb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['दख य नह ',\n",
       " 'लकन बतचत वफल ह गई ह',\n",
       " 'कतर म इतजर करन कड धप म खड रहन इसस उनह कई फरक नह पड रह थ  ',\n",
       " 'लग म य ह अफरतफर मच गई थ',\n",
       " 'इस फन म 20 मगपकसल क फरट कमर दय गय ह',\n",
       " 'दल सबधत परशनय',\n",
       " 'भगवन वषण क छठ अवतर मन जन वल परशरम ज क सहस क दवत मन जत ह',\n",
       " 'इस ममल क पहल जच हन चहए',\n",
       " ' ख अपन भई  बहन क नम यद रखन स हम कस उनह खश दत ह',\n",
       " 'कय गडबड ह']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c530e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ನಡಕಳಳಲ ಇಲಲವಲಲ',\n",
       " 'ಆದರ ಈ ಕರತ ಒಡಬಡಕ ವಫಲವಯತ',\n",
       " ' ಉರಬಸಲದದರ ಸಲನಲಲ ನತ ಕಯವದ ಅವರಗ ಲಕಕಕಕ ಬರಲಲಲ  ಎದ ಹಳದಳ',\n",
       " 'ಇದದಕಕ ಸರವಜನಕರ ಆಕರಶ ವಯಕತಪಡಸದದರ',\n",
       " 'ಇದರ ಮಭಗದ ಪಯನಲಲಲ ಫನಗ 20MP ಮಗಪಕಸಲ ಸನಸರನನ ಫನ ಹದದ',\n",
       " 'ಹದಯ ತದರಗಳ',\n",
       " 'ಪರಶರಮನನ ವಷಣವನ ಆರನ ಅವತರ ಎನನಲಗತತದ',\n",
       " 'ಅದಕಕಗ ಮದಲ ತನಖ ಆಗಬಕಗತತದ',\n",
       " 'ವಯಕತಕ ಆಸಕತಯನನ ತರಸವ ಒದ ವಧ ಯವದ',\n",
       " 'ಯವದ ತಪಪ ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd6f9e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7108, 7731)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(x) for x in kannada_sentences), max(len(x) for x in hindi_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c373a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length Kannada: 103.0\n",
      "97th percentile length Hindi: 107.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length Hindi: {np.percentile([len(x) for x in hindi_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c05acc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of senteces: 210000\n",
      "Number of valid sentences: 205576\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_Valid_Tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_Valide_Length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length-1) #need to re-add the <END> token so leaving space for it\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(kannada_sentences)):\n",
    "    kannada_sentence, hindi_sentence = kannada_sentences[index], hindi_sentences[index]\n",
    "    if is_Valide_Length(kannada_sentence, max_sequence_length) and is_Valide_Length(hindi_sentence, max_sequence_length) and is_Valid_Tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "        \n",
    "# print(valid_sentence_indicies)\n",
    "print(f\"Number of senteces: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84a33842",
   "metadata": {},
   "outputs": [],
   "source": [
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
    "hindi_sentences = [hindi_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "197b3f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ನಡಕಳಳಲ ಇಲಲವಲಲ',\n",
       "  'ಆದರ ಈ ಕರತ ಒಡಬಡಕ ವಫಲವಯತ',\n",
       "  ' ಉರಬಸಲದದರ ಸಲನಲಲ ನತ ಕಯವದ ಅವರಗ ಲಕಕಕಕ ಬರಲಲಲ  ಎದ ಹಳದಳ',\n",
       "  'ಇದದಕಕ ಸರವಜನಕರ ಆಕರಶ ವಯಕತಪಡಸದದರ',\n",
       "  'ಹದಯ ತದರಗಳ'],\n",
       " ['दख य नह ',\n",
       "  'लकन बतचत वफल ह गई ह',\n",
       "  'कतर म इतजर करन कड धप म खड रहन इसस उनह कई फरक नह पड रह थ  ',\n",
       "  'लग म य ह अफरतफर मच गई थ',\n",
       "  'दल सबधत परशनय'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:5], hindi_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c858d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "kn_vocab_size = len(kannada_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          kn_vocab_size,\n",
    "                          hindi_to_index,\n",
    "                          kannada_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3234ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, hindi_sentences, kannada_sentences):\n",
    "        self.hindi_sentences = hindi_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hindi_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.hindi_sentences[idx], self.kannada_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3fc68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(hindi_sentences, kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4c616ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205576"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e94e5514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['दख य नह '], ['ನಡಕಳಳಲ ಇಲಲವಲಲ'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3975ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f606c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('दख य नह ', 'लकन बतचत वफल ह गई ह', 'कतर म इतजर करन कड धप म खड रहन इसस उनह कई फरक नह पड रह थ  ', 'लग म य ह अफरतफर मच गई थ', 'दल सबधत परशनय', 'भगवन वषण क छठ अवतर मन जन वल परशरम ज क सहस क दवत मन जत ह', 'इस ममल क पहल जच हन चहए', ' ख अपन भई  बहन क नम यद रखन स हम कस उनह खश दत ह', 'कय गडबड ह', 'उनहन सबधत अधकरय क लग क समसयओ क नरकरण करन क नरदश दय', 'उनक खब लइकस और कमटस भ मल', 'नब क रस नमक कल मरच आद डलकर अचछ तरह मलकर सरव कर', 'इसक जवब त समय ह दग', 'बच बचव करन आय म क भ उसन गल मरकर घयल कर दय', 'यह सरकर तयहर नह ह', 'अभ इसक नरकरण नह ह सक ह', 'कसन कस ज रह ह', 'करकषतर क 100 करड', 'मरठ म चर कनपर फरजबद और बजनर म दद वरणस सभल और मजफफरनगर म एकएक क मत हई ह', '30 नवबर 2015 क परधनमतर क सओप21 सममलन परस म दय गय वकतवय', 'वकसन क कई सईड इफकट नह ह', 'लकन फर भ कस न कस वजह स यह बत टलत चल गई', 'इसक वजह भ रचक ह', 'इस गन क रणवर कपर और दपक पदकण पर फलमय गय ह', 'लकन यह परसकर वशष ह', 'पहल दसर व तसर सथन पर रहन वल परतभगय क मखयतथ न परसकर दकर सममनत कय', 'आखरकर कटपप न बहबल क कय मर थ', 'इनह रजन करक आप अपन शरर क मजबत कर सकत ह', 'बशन सह बद 67 मच म 266 वकट', 'इसक लए सरकर न 25 लख डलर क फड भ बनय'), ('ನಡಕಳಳಲ ಇಲಲವಲಲ', 'ಆದರ ಈ ಕರತ ಒಡಬಡಕ ವಫಲವಯತ', ' ಉರಬಸಲದದರ ಸಲನಲಲ ನತ ಕಯವದ ಅವರಗ ಲಕಕಕಕ ಬರಲಲಲ  ಎದ ಹಳದಳ', 'ಇದದಕಕ ಸರವಜನಕರ ಆಕರಶ ವಯಕತಪಡಸದದರ', 'ಹದಯ ತದರಗಳ', 'ಪರಶರಮನನ ವಷಣವನ ಆರನ ಅವತರ ಎನನಲಗತತದ', 'ಅದಕಕಗ ಮದಲ ತನಖ ಆಗಬಕಗತತದ', 'ವಯಕತಕ ಆಸಕತಯನನ ತರಸವ ಒದ ವಧ ಯವದ', 'ಯವದ ತಪಪ ', 'ಸಥಳಯರ ಸಮಸಯಯ ಬಗಗ ಮಲಧಕರಗಳಗ ತಳಸವದಗ ಹಳದರ', 'ಇದಕಕ ಭರ ಸಖಯಯಲಲ ಲಕಸ ಕಮಟ ಬದದ', 'ಅದಕಕ ಅರಶನ ಇಗ ಬಲಲ ಉಪಪ ಹಕ ಮಶರ ಮಡ ಕಲಸಕಳಳಬಕ', 'ಸಮಯವ ಉತತರಸಬಕ', 'ಅಲಲದ ನತರರ ತಯಯ ಮಲ ಹಲಲ ಮಡ ಕಲ ಯತನಕಕ ಮದಗದದನ', 'ಇದದ ಸರಕರದ ಹಬಬವಲಲ ಎದ ಶ ಹಳದದರ', 'ಅದನನ ಇನನ ಬಡಸಲ ಸಧಯವಗಲಲಲ', 'ಹಗದರ ರತರ ಬದಕವದದರ ಹಗ ', '100 ಕಟ ರ ಡಲ', 'ಮರತನಲಲ ಐವರ ಕನಪರ ಬಜನರ ಹಗ ಫರಜಬದನಲಲ ತಲ ಇಬಬರ ಮಝಪಫರನಗರ ಸಭಲ ರಪರ ಹಗ ವರಣಸಯಲಲ ತಲ ಒಬಬರ ಮತಪಟಟದದರ', '2015ರ ನವಬರ 30ರದ ಪಯರಸ ನ ಕಪ 21ರಲಲ ಪರಧನಮತರಯವರ ಹಳಕ', 'ಔಷಧದ ಇತರ ಅಡಡಪರಣಮಗಳ ಅಲಲ ಹದದ', 'ಆದರ ಕರಣತರಗಳದ ರಜ ಮದಡದದರ ಎನನಲಗದ', 'ಅದಕಕ ತಕಕ ಕರಣವನನ ನಡದದರ', 'ಈ ಚತರದ ಶಟಗ ವಳ ದಪಕ ಹಗ ರಣವರ ಸಗ ನಡವ ಪರತ ಚಗರತತ', 'ಆದರ ಇದರಲಲ ವಶಷ ಇರವದ', 'ಆಯಕಯಗ ಪರಥಮ ದವತಯ ಹಗ ತತಯ ಸಥನ ಪಡದ ಪರಢ ಶಲ ವಜತರದ ವದಯರಥಗಳಗ ಬಹಮನ ನಡಲಯತ', 'ಬಹಬಲಯನನ ಕಟಪಪ ಯಕ ಕದ', 'ಇದನನ ಪರತದನ ಮಡದರ ನಮಮ ದಹದ ಸನಯಗಳನನ ಬಲಪಡಸಲ ಸಹಕರಯಗದ', 'ಬಷನ ಸಗ ಬಡ  67 ಪದಯಗಳದ 266', 'ಇದಕಕಗ ಸರಕರ ಬರಬಬರ 25 ಕಟ ರಪಯ ಹಣವನನ ಬಡಗಡಗಳಸದ')]\n",
      "[('सभ क नयम क पलन करन हग', 'कस स कछ बल नह', 'इटलयन सकटर नरमत कपन अपन आगम मडलस क लए फयल इजकटड ससटम ल रह ह', 'डर कह रहत ह', 'इसम मन कन स धखधड़ क', 'पलस न परतदवदव समह क लग क ततरबतर करन क लए बल क इसतमल कय', 'इस बर म परट क नरणय करन ह', 'महभरत क करण क करदर नभएग शहद कपर', 'म ज कह रह ह वह सच ह', 'उनह और पन चहए', 'घयल क असपतल म पहचय गय मक पर रहत एव बचव करय जर', 'चयन परकरय जनयर इजनयर पद क लए उममदवर क चयन लखत परकष इटरवय क आधर पर चयन हग', 'कय ह परइज मन', 'घरवल न दरज करई पलस म रपरट', 'यश न ऐस कम कए जसस दसर क सरफ कछ पल क लए नह बलक हमश  हमश क लए फयद मल ', 'एक सभ म 15 लख र', 'मझ टम क कषमत पर जर भ शक नह ह', 'परम सग मलकर करई थ पत क हतय', 'इसम बतय गय बत बलकल नय ह ', 'लयमसन ड', 'और दल म सग वशवसय क लए पयर हन क वजह स ह व मदद क लए फरन आग आत ह   यहनन 13 34 35', 'तन बर ससद रह हए ह', 'नह हआ समधन', 'जसक लकर बजप न शकयत कय थ', 'लकन करन क मझ कछ नह मल', 'कय ऐस पहल नह हआ ह', 'मगर इस कषतर क वकस नह कय ज रह ह', 'अगल दन एक सनक न दय करक मझ रट और पन दय और पहनन क लए एक कट भ दय ', 'हलक वह कछ कम कए जन क जररत हग', 'इस तलमल क आप कस दखत ह'), ('ಎಲಲರ ನಯಮಕಕನಸರವಗ ನಡದಕಳಳಬಕ', 'ಯರಗ ಯವದನನ ಹಳರಲಲಲ', 'ಇದಗ ಭವಷಯದಲಲ ಮರಟವಗಲರವ ಮದರಗಳಗ ಫಲಯಲ ಇಜಕಟಡ ತತರಜಞನ ಅನಸರಸಲ ಇಟಲ ಮಲದ ಸಕಟರ ತಯರಕ ಸಸಥಯ ನರಧರಸದ', 'ಎಲಲ ಓಡತರ ಹದರ', 'ಪಟಟ ತನನವತಹ ಕಲಸ ಏನ ಮಡದದ ನನ', 'ಜನರ ಗಪನನ ಬಲ ಪರಯಗಸ ಚದರಸಲ ಪಲಸರ ಯತನಸದದರ', 'ಈ ಬಗಗ ಪಕಷ ತರಮನ ಮಡತತ', 'ಶಹದ ಕಪರ ಕಬರ ಸಗ ಪತರದಲಲ ಮಚದದರ', 'ನನ ಹಳರದ ಸರಯಗ ಇದ', 'ಅವ ನರಗ ಪರದಡಬಕಗದ', 'ಗಯಗಡವರನನ ಆಸಪತರಗ ಸಗಸಲಗದದ ರಕಷಣ ಕರಯ ಭರದದ ಸಗದ', 'ಆಯಕ ವಧನ ಮಲನ ಎರಡ ಹದದಗಳಗ ಅಭಯರಥಗಳನನ ವಯಕತಕ ಸದರಶನ ಹಗ ಮಲ ದಖಲತಗಳ ಪರಶಲನ ಮಲಕ ಆಯಕ ಮಡಲಗತತದ', 'ಏನದ ನಗದ ಪರಸಕರ', 'ಕಟಬಸಥರ ಪಲಸ ಠಣಯಲಲ ದರ ನಡದದರ', 'ಇತರರಗ ನರತರ ಒಳತನನ ತರವದರ ಮಲ ಯಸ ತನನ ಗಮನವನನ ಕದರಕರಸದನ', ' ಮಮಮಟ 15 ಲಕಷ ರ', 'ತಡದ ಸಮರಥಯದ ಬಗಗ ಸವಲಪವ ಅನಮನವಲಲ', 'ಆತಮಯ ಸನಹತನ ಸಗ ಮಡದವಳ ಹತಯ ಮಡದ ಪತ', 'ನಮಗದ ಹಸ ವಷಯ ', 'ಲಯಮಸನ ಬ', 'ಏಕದರ ಕರಸತರಗ ಸಹದರರ ಪರಮವ ತನ ಅಗತಯದಲಲರವ ಜತ ವಶವಸಗಳಗ ಸಹಯವನನ ನಡವತ ಪರಚದನಯನನ ನಡತತದ   ಯಹನ 13  34 35', 'ಮರ ಬರ ಶಸಕರಗದದರ', 'ಪರಹರ ಕಟಟಲಲ', 'ಇದರ ವರದಧ ಬಜಪ ಯವ ವಭಗ ದರ ನಡದ', 'ಆದರ ನನ ಏನ ಮಡವ ಹಗ ಇರಲಲಲ', 'ಹದದ ಹಗಗರಲಲಲ', 'ಆದರ ಸಥಳಯ ಸಪನಮಲ ಪರದಶದ ಅಭವದಧಗ ದರಯತತಲಲ', 'ಒದ ಕಬಳ ಕಡ ಇರಲಲಲ', 'ಆದರ ಆದಗಯ ಮಡಲ ಕಲಸ ಹದರತತದ', 'ಅತಹ ಸಬಧವನನ ರಪಸವ ಬಗಗ ನವ ಹಗ ಹಗತತರ')]\n",
      "[('ह मर पतर यद त अपन पडस क उततरदय हआ ह अथव परदश क लय हथ पर हथ मर कर उततरदय हआ ह', 'इस फलम क रलज डट पस आ चक ह', 'वनसपत और जव ', 'पर दनय इस अचछ स जनत ह', 'इनहन बड हममत क सथ शतन क दषट दनय क खलफ यहव क नययदड सनय ', 'आखर ऐस कय हत', 'कटरवरस कय ह', 'रषटरपत शर परणब मखरज न वखयत सरग वदक उसतद सबर खन क नधन पर शक वयकत कय ह', 'कय ह खतरनक', 'आपक कई चरज नह लगग', 'हम कस दख सकत ह क हमर वशवस मजबत ह', 'दन न इस बत पर भ सहमत जतई क भरतऑसटरलय रणनतक सझदर दन दश क कवड19 स सबधत चनतय स नपटन क लए अनय दश क सथ मलकर कम करन क एक अचछ आधर परदन करत ह', 'ववद क बचतत क जरए सलझन चहए', 'कहकर उततर मल', 'बद म य 10 लख रपय ह गय', 'जसक बद यह बल कनन बन गय', 'वतत मतर नरमल सतरमण न कह ह क परव परधनमतर मनमहन सह और आरबआई क परव गवरनर रघरम रजन क करयकल सरकर बक क लए सबस खरब थ', 'जल क बद ऊपर क खच लत ह व कहर स मह हकर टपकत ह व ऊच ऊच बदल उडलत ह और मनषय क ऊपर बहतयत स बरसत ह  ', 'सड़क पर आ जएग', 'सशल मडय पर इसक परचर भ शर ह चक ह', 'इस अवसर पर उपमडल अधकर नगरक जगदश शरम नगरनगम क सयकत आयकत सजन सह एचसएस अधकर सजय रय महदर पल सह नगरधश आशम सगवन एएसप वकस धनखड क अलव सभ वभग क आलधकरगण उपसथत थ', 'कस स कह', 'इसस मर लए एक बड थरप क कम कय', 'इसक बन हम नह ज सकत ह', 'हम सब सटडट ह', 'बचच पढ़ रह थ', 'ऐस बनए अलस क चय', 'यवत क एक अनय यवक स परम परसग चल रह थ', 'pmc bank case सपरम करट न बमब हईकरट क फसल पर लगई रक जर रहग सपतत क नलम क परकरय', 'हम इस दश म आवशयक क़दम उठ रह ह'), ('ನನನ ಮಗನ ನನನ ಸನಹತನಗಗ ನನ ಹಣಯಗದದರ ಪರನದಗ ನನನ ಕಯನನ ಒಡಡದದರ', 'ಈಗಗಲ ಚತರಕರಣ ಮಗಸರವ ಚತರತಡ ಬಡಗಡಗ ದನಕ ನಗಧ ಮಡದ', 'ಪರಣ ಮತತ ಸಸಯ ಜವನ', 'ಇದ ಇಡ ವಶವಕಕ ಗತತದ ಎದ ಹಳದದರ', ' ಆದ 5 22  24 6 9 ಸತನನ ದಷಟ ಲಕವನನ ಯಹವನ ನಶಮಡವನದ ಅವರಬಬರ ಧರಯದದ ಸರಹಳದರ', 'ಫಲತಶ ಯಕ ಹಗಯತ', 'ಕಜಷನ ಎದರನ', 'ಖನ ಅವರ ನಧನಕಕ ಭರತದ ರಷಟರಪತಗಳದ ಶರ ಪರಣಬ ಮಖರಜಯವರ ಸತಪ ಸಚಸದದರ', 'ಯಕ ಅಪಯಕರ', 'ಭರಸವ ಅಗತಯವಲಲ', 'ನಮಗ ಬಲವದ ನಬಕಯದ ಎದ ಹಗ ತರಸಬಹದ', 'ಕವಡ19 ರ ನತರದ ಸವಲಗಳನನ ಎದರಸಲ ಭರತಆಸಟರಲಯ ಕರಯತತರದ ಸಹಭಗತವವ ಇತರ ದಶಗಳದಗ ಒಗಗಡ ಕಲಸ ಮಡಲ ಉತತಮ ಅಡಪಯವನನ ಹಕದತಗತತದ ಎದ ಕಡ ಅವರ ಒಪಪಕಡರ', 'ವವದವನನ ಶತ ಸಹರದಯತವಗ ಬಗಹರಸಬಕ ಎದರ', 'ಉತತರ ಬತ', 'ಆ ನತರ 10 ಕಟ ರ', 'ಕರಮಣ ಮಸದ ಕನನ ಆಯತ', 'ಮಜ ಪರಧನ ಡ ಮನಮಹನ ಸಗ ಮತತ ಆರ ಬಐ ಹದನ ಗವರನರ ರಘರಮ ರಜನ ಅವರ ಅವಧಯಲಲ ಭರತದ ಸರವಜನಕ ವಲಯ ಬಯಕಗಳ ಸಥತ ಅತಯತ ಶಚನಯ ಹತಕಕ ತಲಪತತ ಎದ ಕದರ ವತತ ಖತ ಸಚವ ನರಮಲ ಸತರಮನ ಹಳದದರ', 'ಒದ ವಜಞನಕ ಪಠಯಪಸತಕವದ ಹಡರಲಜ ಇನ ಪರಕಟಸ ಹಳವದ ಮಡದ ಸಕಷಮ ಹನಗಳ ಹಗ ಮಳ ಹನಗಳಗತತವ ಎಬದಕಕ ಹಲವರ ನರಪಣಗಳವ', 'ಬದಗ ಬರಬಕ', 'ಅಲಲದ ಸಮಜಕ ಜಲತಣದಲಲ ಇದರ ವರದಧ ಅಭಯನ ಆರಭಸದ', 'ಸಭಯಲಲ ಜಲಲ ಪಚಯತ ಸಇಓ ಪರತ ಗಹಲತ ಎಸಪ ವಷಣವರಧನ ಕದಪರ ಉಪ ಅರಣಯ ಸರಕಷಣಧಕರ ಆಶಶ ರಡಡ ಕದಪರ ಉಪ ವಭಗಧಕರ ರಜ ಅಪರ ಜಲಲಧಕರ ಸದಶವ ಪರಭ ಹಗ ಎಲಲ ಜಲಲ ಮಟಟದ ಅಧಕರಗಳ ಉಪಸಥತರದದರ', 'ಯರಗ ಹಳದ ', 'ಇವಗಳ ನನಗ ಚನನಗ ಮಡದದವ', 'ನವ ಬದಕಲ ಸಧಯವಲಲ', 'ನವ ಎಲಲರ ಮಕಕಳಲಲ ಆಟವಡತತವ', 'ಮಕಕಳಗ ಕವಮತ ಹಳದರ', 'ಚಹ ಕದಸವದ ಹಗ', 'ಯವತಗ ಈಚಗ ಮತತರವ ಯವಕನ ಜತ ಮದವಯಗದದಳ', 'ಪಎಸ ಬಯಕ ಹಗರಣ ಆರಪಗಳನನ ಜಲನದ ಸಥಳತರದ ಆದಶಕಕ ಸಪರ ತಡಯಜಞ', 'ಈ ನಟಟನಲಲ ಈ ಕಲಸಕಕ ಸಣಣ ಹಜಜ ಇಡತತದದವ')]\n",
      "[('50 लख करड रपय', 'परधनमतर तमलनड क रजमरग अवसरचन क वयपक परतसहन दत हए रषटरय रजमरग सखय45स क वकरवदसतयतपप खड सतयतपपचलपरम खड और चलपरम तजवर खड क चर लन क बनन क आधरशल रखग', 'लकन सब वस ह नह हत जस हम चहत ह', 'और ज लग पशचतप करक बपतसम ल रह थ व उनह तचछ समझ रह थ ', 'हम पत ह क सथत कय ह', 'कमपयटर चरज ह रह ह', 'एक और ह', 'बतय ज रह ह क हदस क बद बस क डरइवर फरर ह गय', 'सतर न जवब दय सरप न मझ बहक दय तब म न खय  ', 'लकन समसय क हल नह नकल', 'यह ह असल हदसतन पवर', 'सपरम करट म कगरस क दलल', 'यह व मनत ह', 'टम इडय क नई जरस', 'जड़ नह वह', 'अभ कस क फइनल नह कय गय ह', 'सदर असपतल म इलज क दरन ह बचच क मत ह गई', 'यह एक आम बत बन गय थ', 'हम थक गए ह', 'यद रखए यह समय सवल पछन क नह ह खसकर नज सवल ', 'उस तरह आज हमर समय म भ दषट पर यहव क नयय क दन  वग  स चल आ रह ह ', 'यह गसट हउस कसक ह', 'दवद अपन हद जनत थ ', 'decentralization क दवर इसक आग बढन क परयस कय', 'सवधन सभ क बहस चल', 'जलद स जलद सखत कररवई क जए', 'मक पर पलस क खन पड मल', 'हमर खद क कम हत ह', 'इसक पछ कनगरस ह', 'उनहन चनव लडन क बत नह कह'), ('ಹಗ ಮಲಸಕರಯಕಕಗ 15 ಕಟ ರ', 'ತಮಳನಡನಲಲ ಹದದರ ಮಲಸಕರಯಕಕ ಪರಮಖ ಉತತಜನವಗ ಪರಧನಮತರ ಅವರ ರಷಟರಯ ಹದದರ ಎನಎಚ45 ಸ ಯ ವಕರವಡಸಥಯಥಪ ಸಕಷನ ಸಥಯಥಪ ಚಲಪರ ಸಕಷನ ಮತತ ಚಲಪರ ತಜವರ ಸಕಷನ ಗಳ ಚತಷಪಥಕಕ ಶಲನಯಸ ಮಡವರ', 'ಆದರ ಎಲಲವ ಅದಕಡತ ಆಗವದಲಲ', 'ಇವರ ಪಶಚತತಪಪಟಟ ದಕಷಸನನ ಹದತತದದ ಜನಸಮನಯರನನ ತಚಛವಗ ಕಣತತದದರ', 'ಪರಸಥತ ಯವದದ ನಮಗರವದ', 'ಗಣಕವ ಚರಜ ಆಗತತದ', 'ಇನನಬಬರ ಬರತತರ', 'ಢಕಕಯ ರಭಸಕಕ ಬಸ ಕಮರಗ ಉರಳದದ ಬಸ ಚಲಕ ಪರರಯಗದದನ ಎನನಲಗದ', 'ಆಗ ಸತರ ಅದದದ ಸರಪವ ನನನನನ ವಚಸತ ನನ ತದನ ', 'ಆದರ ಸಮಸಯಗಳಗ ಸಕತ ಪರಹರ ದರತತಲಲ', 'ಇದನ ಭರತದ ಶಕತ ಎದ ಪರಶನಸದದರ', 'ಸಪರ ಕರಟಗ ಕಗರಸ ಮರ', 'ಈ ಅವರ ನಬಕಸತ ಎದರಥ', 'ಟ ಇಡಯ ಹಸ ಜರಸ', 'ಅಲಲ ಜನವಸವಲಲ', 'ಈ ಪರಕರಣ ಇನನ ಇತಯರಥವಗಲಲ ಎದ ಪತರದಲಲ ತಳಸದದರ', 'ಆಸಪತರಯಲಲ ಚಕತಸ ಫಲಕರಯಗದ ಮಗ ಸವನನಪಪತತ', 'ಆಮಶಕ ಸಮನಯವಗತತ', 'ದಣದದದವ', 'ನಮಮ ಮತರನ ತನನ ಕಯಲಯ ಕರತ ವಷಯಗಳನನ ಬಹರಗಗಳಸಲ ಇಚಛಸದರವಗ ಅದನನ ಮನಯಮಡ', 'ದಷಟ ಜನರ ನಶನಕಕಗ ದವರ ಸದಧವಗಟಟರವ ಸವರಗಯ ಶಸತರಸತರಗಳ ಮದ ಸದಯದ ದಷಟ ವಷಯಗಳ ವಯವಸಥಯ ಈ ಕಟಕತತಲಗಳ ಅಷಟ ನಷಪರಯಜಕವಗರವವ', 'ಹಗರಲ ಈ ಮನ ಯರದ', 'ಅವನಗ ತನನ ಇತಮತಗಳ ಅರವತತ', 'ಒಟಟನಲಲ ವಕದರಕರಣವನನ ಜರಗ ತರವ ಮಲಕ ನವ ಈ ಪರಕರಯಗಳನನಲಲ ಸಧರಸಲ ಪರಯತನಸತತದದವ', 'ಸದರಭಕ ಅಸಬಲ ಚರಚಗಳ', 'ಆದಷಟ ಬಗ ಶಸತ ಕರಮ ಜರಗಸಬಕ', 'ಪಲಸರ ಸಥಳಕಕ ಧವಸದದರ', 'ನಮಮ ಪಡಗ ನವ ದಡಯತತದದವ', 'ಇದರ ಹದ ಷಡಯತರ ಇದ ಎದ ನಡದರ', 'ಅವರ ಚನವಣಯಲಲ ಸತ ಇರಲಲಲ')]\n",
      "[('बजप क ववदत ससद और अपन ', 'महल क जखम हलत म असपतल म भरत करय गय', 'द सनम ओनरस एड एगजबटरस एससएशन ऑफ इडय सओईएआई न फसल लय ह क व पकसतन कलकर क अभनय वल कस भ फलम क परदरशन नह करग', 'शर नरनदर मद न कह क इस दन और कल म जल सरकषण हमर लए एक बड चनत ह', '5 करड रपय थ', 'अगर उनक इसतमल करन पड जय त कस करग', 'फलम क कहन म तन परमख पतर हग', 'इस फलम क नरदशन महश भटट न कय ह', 'कसन क दखदरद क हमन समझ', 'नरदर मद न यह बत फरस म अमरक क रषटरपत डनलड टरप क सथ एक सयकत परस कनफरस क दरन कह', 'उनहन कह हम वरत एव वचरवमरश क जरए समसयओ क उचत तरक स सलझन म सकषम ह', 'ज जय पए और मर कम क अनसर अनत तक करत रह म उस जत जत क लग पर अधकर दग', 'म बत नह कर सकत', 'कय हआ य ममल', 'वह ल गरजएट थ', 'महरषटर इलकशन वच क रजयसमनवयक शरद कमर न कह जब तक लग बड सखय म मतदन करन घर स बहर नह नकलग तब तक रजनतक परटय धन और बहबल उममदवर क चयन करग', 'लकन इस गठबधन स बसप क कई फयद नह मल', 'हर परकर क कल अलग व वशषट ह', 'कमर क सथ डयल led फलश भ द गई ह', 'उनहन मग क ड', 'एक बउल म मद नमक चन कलज एक सथ मकस कर ल', 'दलल गगरप क जस ममल', '100 सअधककलकरएकलडसमभगलग', 'इतन सबकछ करन क बद भ बहत क लगत ह क सचच खश उनस कस दर ह ', 'ठड हन पर इस कस एअर टइट कनटनर म भरकर रख', 'बस कर', 'ज ह यहव सरफ उनह पररथनओ क सनत ह ज उसक बतए हए तरक स क गय ह ', 'व करत ह', '250 गरम भड', 'पलवम हमल क बद भरत क सखत तवर क बच पकसतन घबरय हआ ह'), ('ಬಜಪ ಮತತ ಪಕಷತರ ವಜತ ಅಭಯರಥ', 'ಘಟನಯಲಲ ಗಭರ ಸವರಪದ ಗಯಗಡ ಮಹಳಯನನ ಆಸಪತರಗ ದಖಲಸಲಗದ', 'ಪಕಸತನ ಕಲವದರ ನಟಸರವ ಚತರಗಳ ಬಡಗಡಗ ಭರತಯ ಸನಮ ನರಮಪಕರ ಹಗ ಪರದರಶಕರ ಸಘಟನಯ ನಷಧ ಹರದ', 'ಈ ಯಗದಲಲ ಮತತ ಸಮಯದಲಲ ನಮಗ ಜಲ ಸರಕಷಣ ಬಹದಡಡ ಸವಲಗದ ಎದ ಪರಧನ ನರದರ ಮದ ಹಳದರ', 'ಇದ ಹಣವನನ 5 ಕಟ ರ', 'ಅವಗಳನನ ಸರಯಗ ಹಗ ಬಳಸವದ', 'ಮವರ ನಟಯರ ಚತರದ ಮಖಯ ಆಕರಷಣ', 'ಅತರಥ ಚತನ ಅಭನಯದ ಮಹಶ ಬಬ ನರದಶನದ ಈ ಚತರಕಕ ಮಹಶ ಬಬ ನರದಶಕ', 'ನಮಗ ರತರ ನವ ಅರಥವಗತತದ', 'ಡನಲಡ ಟರಪ ಜತ ಜಟ ಪತರಕಗಷಠ ಉದದಶಸ ಮತನಡದ ಸದರಭ ಮದ ಅವರ ಈ ವಷಯ ಬಹರಗಪಡಸದದರ', 'ಮತಕತ ಮತತ ಸಮಲಚನಯ ಮಲಕ ನಮಮ ನಡವನ ಸಮಸಯಗಳನನ ಸರಯಗ ಪರಹರಸಲ ನವ ಸಮರಥರಗದದವ', 'ಯವನ ಜಯಹದ ನನನ ಕರಯಗಳನನ ಕಡವರಗ ಕಕಳಳತತನ ಅವನಗ ನನ ಜನಗಗಳ ಮಲ ಅಧಕರವನನ ಕಡ ತತನ', 'ನನಗ ಮತನಡಲ ಬರವದಲಲ', 'ಇದ ಯಕ ಹಗಯತ', 'ಕನನ ಪದವಧರರಗದದರ', 'ಮತದರರ ದಡಡ ಪರಮಣದಲಲ ಮತ ಹಕಲ ಹಗವ ತನಕ ರಜಕಯ ಪಕಷಗಳ ಹಣ ಹಗ ತಳಬಲ ಇರವ ಅಭಯರಥಗಳನನ ಮತರವ ಕಣಕಕ ಇಳಸತತವ ಎದ ಮಹರಷಟರ ಎಲಕಷನ ವಚ ಸಘಟನ ಸಚಲಕರಗರವ ಶರತ ಕಮರ ಹಳತತರ', 'ಆದರ ಬಜಪ ಇದರ ಲಭವನನ ಪಡದಕಳಳಲ ಮದಗಲಲ', 'ಪರತ ಚತರಕಲಯ ಒದಕಕದ ಭನನವಭನನ', 'ಕಯಮರ ಮಲಕ ಒದ ಎಲಇಡ ಫಲಶ ಹದದ', 'ಕಲಗರತ ಅವರ ಆಗರಹಸದದರ', 'ಒದ ಬಟಟಲನಲಲ ಬರತ ರವ ಸಕಕರ ಮತತ ಮಸರ', 'ದಹಲ ಸಮಹಕ ಅತಯಚರ ವಚರಣಯ ವರದ', '100ಕಕ ಹಚಚ ಪರಮಖ ಕಪನಗಳ ಉದಯಗ ಮಳದಲಲ ಭಗಯಗವ', 'ಮನವರಲಲ ಹಟಟನದಲ ಆಧಯತಮಕತಗಗ ಹಬಲ ಇದ', 'ಕಲಗ ನತರ ಅದನನ ಮಚಚದ ಧರಕದಲಲ ಇರಸ', 'ಹ ಹಹ ಹಹ ಹಹ', 'ಅತಹ ಪರರಥನಗಳ ಕರತ ಯಸ ಏನ ಹಳದನ ಎಬದನನ ಗಮನಸರ', 'ಅವರನ ಮಡರತರ', '250 ಕ ಜ ತಗರ ಬಳ', 'ಪಲವಮ ಉಗರ ದಳಯ ನತರ ಭರತಪಕಸತನದ ನಡವ ಪರಕಷಬಧ ವತವರಣ ನರಮಣವಗತತ')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bad2026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bcc7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(hindi_batch, kn_batch):\n",
    "    num_sentences = len(hindi_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "        hindi_sentence_length, kn_sentence_length = len(hindi_batch[idx]), len(kn_batch[idx])\n",
    "        hindi_chars_to_padding_mask = np.arange(hindi_sentence_length + 1, max_sequence_length)\n",
    "        kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "        encoder_padding_mask[idx, :, hindi_chars_to_padding_mask] = True\n",
    "        encoder_padding_mask[idx, hindi_chars_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "        decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "        decoder_padding_mask_cross_attention[idx, :, hindi_chars_to_padding_mask] = True\n",
    "        decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abc8b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0 : 5.579479694366455\n",
      "English: दख य नह \n",
      "Kannada Translation: ನಡಕಳಳಲ ಇಲಲವಲಲ\n",
      "Kannada Prediction: ಼==9ಮಮಮ9ಮಞಮಮಎ=ಏಏೄಏೄಃೄಘಘಘಘಘಏಘೄ99/ಘ9ೄೄ9ೄೄ91ೄೄೆಘಘಘಘ ೄಏೄಏೄೄೄೄ9ೄೄೄೄ9ತಘಘಘೄೄಏೄೄೄಏ9ೄ1ೄೇ//ూೄೄೄಏಏ,9-9999999-,9ಏ9ూಏ1111ಛೆತ9ೆಏ99>99ತ ತ1ಏಏಏತ  ೆಏಏಏಏಏಞೄ1ೄೇೄೆೄೄೄೄೄ>ತೄ9ತೄೄತೆೇ1ೇ1ೇೇ1ಏ1ೄ111೮೮೮೮ೇ೮ಏ1- 1ೇೇೆೇೇೇೇ೮ೇೇೇೆ಼಼ೇ೮ೇೆೇ9\n",
      "Evaluation translation (क्या हमें मॉल जाना चाहिए?) : ('                                                                                                                                                                                                        ',)\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask \u001b[38;5;241m=\u001b[39m create_masks(hindi_batch, kn_batch)\n\u001b[1;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m kn_predictions \u001b[38;5;241m=\u001b[39m transformer(hindi_batch,\n\u001b[1;32m     15\u001b[0m                              kn_batch,\n\u001b[1;32m     16\u001b[0m                              encoder_self_attention_mask\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[1;32m     17\u001b[0m                              decoder_self_attention_mask\u001b[38;5;241m.\u001b[39mto(device), \n\u001b[1;32m     18\u001b[0m                              decoder_cross_attention_mask\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     19\u001b[0m                              enc_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m                              enc_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m                              dec_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m                              dec_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39msentence_embedding\u001b[38;5;241m.\u001b[39mbatch_tokenize(kn_batch, start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterian(\n\u001b[1;32m     25\u001b[0m     kn_predictions\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kn_vocab_size)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     26\u001b[0m     labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:302\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask, enc_start_token, enc_end_token, dec_start_token, dec_end_token)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    293\u001b[0m             x, \n\u001b[1;32m    294\u001b[0m             y, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m             dec_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# We should make this true\u001b[39;00m\n\u001b[1;32m    301\u001b[0m             dec_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# x, y are batch of sentences\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x, encoder_self_attention_mask, start_token\u001b[38;5;241m=\u001b[39menc_start_token, end_token\u001b[38;5;241m=\u001b[39menc_end_token)\n\u001b[1;32m    303\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token\u001b[38;5;241m=\u001b[39mdec_start_token, end_token\u001b[38;5;241m=\u001b[39mdec_end_token)\n\u001b[1;32m    304\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:178\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, self_attention_mask, start_token, end_token)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, self_attention_mask, start_token, end_token): \u001b[38;5;66;03m# x here is the input of batch of english sentences\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentence_embedding(x, start_token, end_token) \u001b[38;5;66;03m# tokenizatoin of that batch of english sentences\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x, self_attention_mask) \u001b[38;5;66;03m# performing self attention mask that means they are allowed to look forward & \u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:71\u001b[0m, in \u001b[0;36mSentenceEmbedding.forward\u001b[0;34m(self, x, start_token, end_token)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, start_token, end_token): \u001b[38;5;66;03m# sentence\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tokenize(x, start_token, end_token)\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     73\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_encoder()\u001b[38;5;241m.\u001b[39mto(get_device())\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:66\u001b[0m, in \u001b[0;36mSentenceEmbedding.batch_tokenize\u001b[0;34m(self, batch, start_token, end_token)\u001b[0m\n\u001b[1;32m     64\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch)):\n\u001b[0;32m---> 66\u001b[0m     tokenized\u001b[38;5;241m.\u001b[39mappend( tokenize(batch[sentence_num], start_token, end_token) )\n\u001b[1;32m     67\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(tokenized)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized\u001b[38;5;241m.\u001b[39mto(get_device())\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:55\u001b[0m, in \u001b[0;36mSentenceEmbedding.batch_tokenize.<locals>.tokenize\u001b[0;34m(sentence, start_token, end_token)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(sentence, start_token, end_token):\n\u001b[0;32m---> 55\u001b[0m     sentence_word_indicies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_to_index[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(sentence)]\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start_token:\n\u001b[1;32m     57\u001b[0m         sentence_word_indicies\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_to_index[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTART_TOKEN])\n",
      "File \u001b[0;32m/media/bhavin/New Volume/Github/Transformer-for-Translation/transformer.py:55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(sentence, start_token, end_token):\n\u001b[0;32m---> 55\u001b[0m     sentence_word_indicies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_to_index[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(sentence)]\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start_token:\n\u001b[1;32m     57\u001b[0m         sentence_word_indicies\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlanguage_to_index[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTART_TOKEN])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'p'"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        hindi_batch, kn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(hindi_batch, kn_batch)\n",
    "        optim.zero_grad()\n",
    "        kn_predictions = transformer(hindi_batch,\n",
    "                                     kn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == kannada_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {hindi_batch[0]}\")\n",
    "            print(f\"Kannada Translation: {kn_batch[0]}\")\n",
    "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in kn_sentence_predicted:\n",
    "                if idx == kannada_to_index[END_TOKEN]:\n",
    "                    break\n",
    "                predicted_sentence += index_to_kannada[idx.item()]\n",
    "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            kn_sentence = (\"\",)\n",
    "            hindi_sentence = (\"क्या हमें मॉल जाना चाहिए?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(hindi_sentence, kn_sentence)\n",
    "                predictions = transformer(hindi_sentence,\n",
    "                                          kn_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_kannada[next_token_index]\n",
    "                kn_sentence = (kn_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                    break\n",
    "            \n",
    "            print(f\"Evaluation translation (क्या हमें मॉल जाना चाहिए?) : {kn_sentence}\") #ನಾವು ಮಾಲ್‌ಗೆ ಹೋಗಬೇಕೇ?\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e29b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
